Although there is the pytorch version code implemented in github, I still want to write it in my own way.
github url:https://github.com/pmixer/SASRec.pytorch/tree/main/python

## TODO:
- [ ] 测试自注意力块的三种实现的效果
- [ ] 测试不同对比学习方式的效果
- [ ] 结合content-aware recommendation的方法进行优化

### 2025.4.24
今天开始阅读论文，大致完成了论文到训练细节之前，接下来是一些总结：
1. 论文主要贡献：提出一种基于自注意力机制的序列推荐模型SASRec（看年份感觉就是Transformer出来之后直接就套壳了）
2. 论文的motivation：前序关于序列推荐的算法主要是基于RNN的和基于马尔可夫链的，前者成本高，训练数据要求大（但是似乎没有具体在论文的前半部分具体论证），后者基于简单的强假设：每一个行为都仅取决于少数前几个行为（有点类似状态转移），就过于局部了。文章就想要找一个balance的方法，既可以考虑全局的信息，又可以考虑局部的信息。
3. 关于推荐算法：因为之前并不熟这个领域，所以想要稍微总结一下里面related work中的内容：
    1. 一般来说推荐算法就是建模用户与物品之间的关系，然后可利用的信息一般就是隐性或显性的历史反馈，对于前者而言建模相对比较困难，因为该反馈仅界定了正样本，而负样本没有被界定，比如：我点击了手机商品，最后买了平板，但是对于购买的历史动作而言，没有明确的表示我点击了平板。
    2. 结合商品的其他属性信息似乎叫content-aware recommendation
    3. 常见方法有矩阵分解的方法：利用内积建模用户与物品之间的交互。也有基于相似度的方法：利用余弦相似度或欧氏距离建模物品与物品之间的相似。
4. 论文方法：感觉模型没有和transformer有很大区别，目前有区别的几个点：1、positional embedding说是用transformer的表现不好。2、Q\K切断联系？（这个有点没明白，猜测是用mask的方式）

然后实践方面目前先把数据下下来，今天给数据处理开个头。

### 2025.4.25
目前已经完成了初步的预处理，因为原文有提供一个数据集，所以我现在正在尝试修改原文预处理方法去匹配上这个数据集
但是目前出现两个问题，使用仓库作者的阈值3会导致数据量变大，而以5为阈值则和提供数据的数据量（行数）一致。
第二个问题就是目前用户和物品id的排序是乱的，我估计是数据在做重新排序之前已经先根据时间戳排过序了，所以现在实验一下
现在第二个实验出来还是不一样，但是通过一系列断言验证发现两个序列的统计属性、分布和化作图之后的结构都是一致的，暂时先认为两个序列是一致的。

现在进行模型搭建。
在实现的时候现在遇到了第一个问题，官方在计算自注意力机制的的时候和论文里的公式并不一致，官方在计算的时候是只对Q做了normalize，最后残差连接也是用这个Q去连接，但是原文是对输入做normalize，残差连接是连回原先的输入，所以这里打算做个实验，两个都试一下：
    1. 官方实现版本：将Qnormalize，残差连接用Q
    2. 原文实现版本：将输入normalize，残差连接用输入

然后大致是自己写了一遍这个版本，还没进行测试，目前学习到了一些东西如下：
    1. 实际上这个attention还是用于建模用户的，就是一个用户行为的建模，最后的结果还是通过用户的行为特征和物品特征做内积交互得到
    2. 但是这里训练时候用的正样本和负样本实际上有点没明白是什么，所以需要进一步弄明白来
目前初步测试模型可以跑通，但是还是需要等待进一步验证

### 2025.4.27
今天首先完成评估指标部分的代码
论文提及的评估指标有两个：
1. Hit Rate@10： 我的理解的话就是预测的top10中是否包含了正样本
2. NDCG@10： 这个就是和排名相关了，如果预测的排名越靠前就越好
论文里也提到了实施的方案，就是将ground truth和随机抽取的100个负样本组成样本，然后获得这些样本的预测结果的排序

在实践中遇到了一个没发现过的报错，记录一下：
表现：在运行的时候突然蹦出来：C:\actions-runner\_work\pytorch\pytorch\builder\windows\pytorch\aten\src\ATen\native\cuda\Indexing.cu:1289: block: [3,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.  其中这里的线程和块的号有很多个都出了问题，这里只列出了其中一个
RuntimeError: CUDA error: device-side assert triggered  这个是最后的报错内容
根据内容首先需要定位具体报错具体位置，因为cuda编程是异步操作，首先还是使用cuda，但是设置环境变量CUDA_LAUNCH_BLOCKING为1去尝试同步纠错。
但是仍然出现问题，那么首先将设备切换为cpu查看是否出错。
仍然出错，但是这一次出现了显著报错，发现是按照仓库代码进行修改后里面有一个地方给模型传入了numpy数组，而不是tensor，所以需要修改。修改后运行通过。

完成评估指标部分的代码后，开始模型训练框架部分的代码编写。因为之前没有接触过推荐算法的训练流程，所以需要学习一下。
    1. 第一步还是一样先处理数据，这里的数据划分就是将之前处理好的数据集按照用户聚合，但是似乎和之前的任务的数据划分不一样，这里并不按照用户进行划分，而是将用户前n-2个行为作为训练，第n-1个行为作为验证，第n个行为作为测试，也就是基于时间划分的方式。这个需要学习一下。
    然后这里实现是用一个warpsampler去构造数据抽样，这里我就直接用torch的dataset和dataloader进行替换。
    2. 第二步就是模型训练，这里的流程还是基本上是一致的。

目前代码已经可以正常运行了，尝试进行优化：
1. 对比学习：这个有点奇怪，虽然没有说，但是官方实现里面实际上使用的就是对比学习的方式，就是在没有被互动的物品中抽取作为负样本，当然这里我也是实现了文档要求的，接下来就是进行实验验证。
2. 多任务学习：这个暂时只有一点思路，就是利用rating信息作为另一个预测任务，但是具体该怎么该模型还需要先想一下。
3. 结合其它信息优化： 这里我想到的就是将rating像positional embedding一样，加入到模型中，然后再进行训练。其它信息的利用就需要先看一下相关content_aware recommendation的论文了。


训练的时候发现了一个很不好的问题，就是使用datalodaer之后训练速度会慢很多，判断是因为dataloader每次都是一个一个去加载的，而官方实现是直接多线程预加载的，导致官方实现一个epoch只需要1-2s，而我的实现需要30s，所以现在试一试换上官方方法
并且现在发现效果也差很多，官方的HDCG @ 10只需要20epoch可以到差不多0.7，而我的只有0.1左右，但是实际上损失的降低是差不多的，感觉可能是评估方式写的有问题，现在一点一点排查
- [x] Dataloader替换官方实现WrapSampler  -->  训练速度得到显著提升，但是指标仍然很低，进一步排查
- [x] 官方评估实现与我的评估实现对比 --> 发现实现上出了我的版本是官方实现版本的合并之外似乎没有什么不一样的
- [x] 排查调用  -->  果然发现问题，有点太蠢了，将传入的参数顺序写反了QAQ，现在更改过来就发现好了很多，这些就是正确了


## result
|   METHOD  | Hit @ 10 | HDCG @ 10   |
|  :----:   |  :----:  |   :----:    |
| SASRec    |  0.8245  | 0.5905      |
| Reproduct |          |             |