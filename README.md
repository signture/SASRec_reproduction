Although there is the pytorch version code implemented in github, I still want to write it in my own way.
github url:https://github.com/pmixer/SASRec.pytorch/tree/main/python

2025.4.24
今天开始阅读论文，大致完成了论文到训练细节之前，接下来是一些总结：
1. 论文主要贡献：提出一种基于自注意力机制的序列推荐模型SASRec（看年份感觉就是Transformer出来之后直接就套壳了）
2. 论文的motivation：前序关于序列推荐的算法主要是基于RNN的和基于马尔可夫链的，前者成本高，训练数据要求大（但是似乎没有具体在论文的前半部分具体论证），后者基于简单的强假设：每一个行为都仅取决于少数前几个行为（有点类似状态转移），就过于局部了。文章就想要找一个balance的方法，既可以考虑全局的信息，又可以考虑局部的信息。
3. 关于推荐算法：因为之前并不熟这个领域，所以想要稍微总结一下里面related work中的内容：
    1. 一般来说推荐算法就是建模用户与物品之间的关系，然后可利用的信息一般就是隐性或显性的历史反馈，对于前者而言建模相对比较困难，因为该反馈仅界定了正样本，而负样本没有被界定，比如：我点击了手机商品，最后买了平板，但是对于购买的历史动作而言，没有明确的表示我点击了平板。
    2. 结合商品的其他属性信息似乎叫content-aware recommendation
    3. 常见方法有矩阵分解的方法：利用内积建模用户与物品之间的交互。也有基于相似度的方法：利用余弦相似度或欧氏距离建模物品与物品之间的相似。
4. 论文方法：感觉模型没有和transformer有很大区别，目前有区别的几个点：1、positional embedding说是用transformer的表现不好。2、Q\K切断联系？（这个有点没明白，猜测是用mask的方式）

然后实践方面目前先把数据下下来，今天给数据处理开个头。

2025.4.25
目前已经完成了初步的预处理，因为原文有提供一个数据集，所以我现在正在尝试修改原文预处理方法去匹配上这个数据集
但是目前出现两个问题，使用仓库作者的阈值3会导致数据量变大，而以5为阈值则和提供数据的数据量（行数）一致。
第二个问题就是目前用户和物品id的排序是乱的，我估计是数据在做重新排序之前已经先根据时间戳排过序了，所以现在实验一下
现在第二个实验出来还是不一样，但是通过一系列断言验证发现两个序列的统计属性、分布和化作图之后的结构都是一致的，暂时先认为两个序列是一致的。

现在进行模型搭建。
在实现的时候现在遇到了第一个问题，官方在计算自注意力机制的的时候和论文里的公式并不一致，官方在计算的时候是只对Q做了normalize，最后残差连接也是用这个Q去连接，但是原文是对输入做normalize，残差连接是连回原先的输入，所以这里打算做个实验，两个都试一下：
    1. 官方实现版本：将Qnormalize，残差连接用Q  [ ]
    2. 原文实现版本：将输入normalize，残差连接用输入  [ ]

然后大致是自己写了一遍这个版本，还没进行测试，目前学习到了一些东西如下：
    1. 实际上这个attention还是用于建模用户的，就是一个用户行为的建模，最后的结果还是通过用户的行为特征和物品特征做内积交互得到
    2. 但是这里训练时候用的正样本和负样本实际上有点没明白是什么，所以需要进一步弄明白来